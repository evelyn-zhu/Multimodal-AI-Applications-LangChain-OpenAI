# ğŸ“š Multimodal AI Applications with LangChain & OpenAI API

_A Comprehensive Framework for Building Multimodal AI Applications Using LangChain and OpenAI._

---

## ğŸŒŸ **Overview**
This repository provides a framework for building **multimodal AI applications**, utilizing **LangChain** and **OpenAI APIs**. It supports processing video, audio, and text data, generating embeddings, and implementing a **Question-Answering (QA)** system.

---

## ğŸ”§ **Features**
- ğŸ¥ **YouTube Video Processing**: Extract audio and generate transcripts for analysis.
- ğŸ“ **Text Embedding**: Leverage OpenAI models for semantic similarity and embeddings.
- â“ **Question-Answering System**: Create a retrieval-based QA system with LangChain.
- ğŸ“‚ **Customizable Framework**: Modular design for real-world adaptability.

## ğŸš€ **Getting Started**

### **2. Set Up the Environment**
Follow these steps to prepare your development environment:

1. **Create and activate a virtual environment**:
   ```bash
   python3 -m venv .venv_multimodal
   source .venv_multimodal/bin/activate
   ```

2. **Install the required dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

### **3. Configure API Keys**
Replace the placeholder in `main.py` with your OpenAI API key:
```python
openai.api_key = "your-openai-api-key"
```
For secure management, consider using a `.env` file or secrets manager.

## ğŸ— **Project Structure**
The project follows a modular design:
```plaintext
Multimodal-AI-Applications-LangChain-OpenAI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ download_video.py    # YouTube video downloader
â”‚   â”œâ”€â”€ transcribe_audio.py  # Audio transcription module
â”‚   â”œâ”€â”€ my_embeddings.py     # Text embeddings processing
â”‚   â”œâ”€â”€ text_loader.py       # Text loader for documents
â”‚   â”œâ”€â”€ qa_system.py        # QA system configuration
â”œâ”€â”€ files/
â”‚   â”œâ”€â”€ transcripts/         # Directory for transcripts
â”‚   â””â”€â”€ embeddings/          # Processed embeddings
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # Project documentation
â””â”€â”€ main.py                # Main script
```

## ğŸ’¡ **Usage**

### **Running the Application**
To process a YouTube video and interact with the QA system, execute the following:
```bash
python main.py
```

### **Example Queries**
Once the QA system is running, you can try queries such as:
* "What is this tutorial about?"
* "What is the difference between training and test datasets?"

## ğŸ“– **Technologies Used**
* **Python 3.11**
* **LangChain** for chaining AI tasks
* **OpenAI API** for embedding generation and transcription
* **yt-dlp** for video processing

## âš– **License**
This project is licensed under the MIT License.

## ğŸ¤ **Contributing**
Contributions are welcome! Please fork this repository and submit a pull request.

## ğŸŒ **Contact**
For questions or feedback, please reach out via GitHub issues or contact the repository owner directly.
